{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "toxic detector with bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Определение токсичности комментариев с помощью BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYI6lG7Z5VDs",
        "outputId": "4ecb3483-da28-49d1-c0e1-8050a76cab50"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "9df4a964-9a0b-41cd-cd34-39f58e17629e"
      },
      "source": [
        "!pip install transformers sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig, AutoModel\n",
        "from transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "1151189f-0322-4976-d6ef-e9ef21ba42ca"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0), n_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOPphdL1YBDh"
      },
      "source": [
        "import pandas as pd\n",
        "#train_df = pd.DataFrame.from_records(__flatten(train_data))\n",
        "#test_df = pd.DataFrame.from_records(__flatten(test_data))\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Программирование/м4 семестр/Диссертация/rutoxic/labeled.csv\", encoding=\"utf8\")\n",
        "df = train_df\n",
        "#df = pd.read_csv(\"/content/drive/MyDrive/Программирование/м4 семестр/Диссертация/jigsaw/jigsaw-toxic-comment-train-google-ru.csv\", encoding=\"utf8\")\n",
        "\n",
        "TOXITY_TYPE = \"toxic\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zYo6wK7locr"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Программирование/м4 семестр/Диссертация/jigsaw/jigsaw-toxic-comment-train-google-ru.csv\", encoding=\"utf8\")\n",
        "\n",
        "df = df[(df[TOXITY_TYPE] == \"1\") | (df[TOXITY_TYPE] == \"0\") | (df[TOXITY_TYPE] == 1) | (df[TOXITY_TYPE] == 0)]\n",
        "df.toxic = df[TOXITY_TYPE].astype(int)\n",
        "\n",
        "tox_df = df[df[TOXITY_TYPE] == 1]\n",
        "nottox_df = df[df[TOXITY_TYPE] == 0]\n",
        "\n",
        "tox_l = len(tox_df)\n",
        "nottox_l = len(nottox_df)\n",
        "\n",
        "\n",
        "df = pd.concat([tox_df, nottox_df[:tox_l]])\n",
        "test_df = df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eI7T7sad_oSy",
        "outputId": "9f5a2890-7222-401b-c27b-355fd19c251c"
      },
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df  = train_test_split(df, test_size=0.2)\n",
        "\n",
        "#train_df = df\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "csJBcHxhjLg3",
        "outputId": "4c2e1c7c-a46f-479e-c11c-35c33c4ac963"
      },
      "source": [
        "'''\n",
        "ins_df = test_df[test_df.insult == 1]\n",
        "notins_df = test_df[test_df.insult == 0]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ins_df, test_ins_df  = train_test_split(ins_df, test_size=0.3)\n",
        "train_notins_df, test_notins_df = train_test_split(notins_df, test_size=0.3)\n",
        "\n",
        "ins_l = len(train_ins_df)\n",
        "notins_l = len(train_notins_df)\n",
        "\n",
        "concat_dfs = [train_notins_df] + [train_ins_df for _ in range(notins_l // ins_l)]\n",
        "\n",
        "train_df = pd.concat(concat_dfs)\n",
        "\n",
        "test_df = pd.concat([test_ins_df, test_notins_df])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CyPXeUVDiuWI",
        "outputId": "fe713766-8a3a-44ab-b460-2c2e7e3230c6"
      },
      "source": [
        "\"\"\"\n",
        "ins_df = train_df[train_df.insult == 1]\n",
        "notins_df = train_df[train_df.insult == 0]\n",
        "\n",
        "ins_l = len(ins_df)\n",
        "notins_l = len(notins_df)\n",
        "\n",
        "concat_dfs = [notins_df[:ins_l], ins_df]\n",
        "\n",
        "train_df = pd.concat(concat_dfs)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v34qYs-Qp22f"
      },
      "source": [
        "'''\n",
        "import re\n",
        "\n",
        "mat_re = r\"\\b((у|[нз]а|(хитро|не)?вз?[ыьъ]|с[ьъ]|(и|ра)[зс]ъ?|(о[тб]|под)[ьъ]?|(.\\B)+?[оаеи])?-?([её]б(?!о[рй])|и[пб][ае][тц]).*?|(н[иеа]|[дп]о|ра[зс]|з?а|с(ме)?|о(т|дно)?|апч)?-?ху([яйиеёю]|ли(?!ган)).*?|(в[зы]|(три|два|четыре)жды|(н|сук)а)?-?бл(я(?!(х|ш[кн]|мб)[ауеыио]).*?|[еэ][дт]ь?)|(ра[сз]|[зн]а|[со]|вы?|п(р[ои]|од)|и[зс]ъ?|[ао]т)?п[иеё]зд.*?|(за)?п[ие]д[аое]?р((ас)?(и(ли)?[нщктл]ь?)?|(о(ч[еи])?)?к|юг)[ауеы]?|манд([ауеы]|ой|[ао]вошь?(е?к[ауе])?|юк(ов|[ауи])?)|муд([аио].*?|е?н([ьюия]|ей))|мля([тд]ь)?|лять|([нз]а|по)х|м[ао]л[ао]фь[яию])\\b\"\n",
        "\n",
        "def clean_texts(texts):\n",
        "    return list(map(lambda x: re.sub(mat_re, \"<мат>\", re.sub(r\"[^\\w\\s\\d]\", ' ', x.replace(\"ё\", \"е\"))), texts))\n",
        "'''\n",
        "def clean_texts(texts):\n",
        "    return texts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBN0cpAaTOuT"
      },
      "source": [
        "train_sentences = clean_texts(train_df[\"comment_text\"].values)\n",
        "\n",
        "#print(train_sentences[0])\n",
        "train_sentences = [str(sentence) for sentence in train_sentences]\n",
        "train_gt = [[int(l)] for l in train_df[TOXITY_TYPE].values]\n",
        "\n",
        "\n",
        "test_sentences = clean_texts(test_df[\"comment_text\"].values)\n",
        "\n",
        "test_sentences = [ str(sentence) for sentence in test_sentences]\n",
        "test_gt = [[int(l)] for l in test_df[TOXITY_TYPE].values]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "52b173ca-4b26-4d4c-c6d7-70d5c4b90a55"
      },
      "source": [
        "from transformers import AutoTokenizer, BertConfig\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True) #bert-base-multilingual-cased sberbank-ai/sbert_large_nlu_ru sismetanin/rubert-toxic-pikabu-2ch DeepPavlov/rubert-base-cased\n",
        "\n",
        "tokenized_texts = [[\"[CLS]\"] + tokenizer.tokenize(sent)[:510]  + [\"[SEP]\"] for sent in train_sentences]\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_gt, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwMEQ1XGYBDt"
      },
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i9kZ2ZLYBDu",
        "outputId": "ab4cf28d-fe1e-45ee-e169-32d74c0e8950"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQl5QxH9YBDv"
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfyNNLRrYBDx"
      },
      "source": [
        "from transformers import AdamW, AutoModelForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsCTp_mporB",
        "outputId": "804a742e-9310-435c-969e-2fcf4d6565ff"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2) #bert-base-multilingual-cased sismetanin/rubert-toxic-pikabu-2ch DeepPavlov/rubert-base-cased\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "QxSMw0FrptiL",
        "outputId": "5520a743-c717-48cf-e95b-ac44a28d268a"
      },
      "source": [
        "warmup_prop=0.1\n",
        "\n",
        "EPOCH_NUM = 2\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "'''\n",
        "num_warmup_steps = int(warmup_prop * EPOCH_NUM * len(train_dataloader))\n",
        "num_training_steps = EPOCH_NUM * len(train_dataloader)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
        "\n",
        "loss_fct = nn.BCEWithLogitsLoss(reduction='mean').to(device)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "f9b167d6-5f1a-49a0-ebb1-9654eee283bb"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "\n",
        "for i in range(EPOCH_NUM):\n",
        "    print('=' * 50, f\"EPOCH {i}\", '=' * 50)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # добавляем батч для вычисления на GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Распаковываем данные из dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        train_loss_set.append(loss[0].item())  \n",
        "        \n",
        "        # Backward pass\n",
        "        loss[0].backward()\n",
        "        \n",
        "        # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "        optimizer.step()\n",
        "\n",
        "        # Обновляем loss\n",
        "        train_loss += loss[0].item()\n",
        "        \n",
        "        # Рисуем график\n",
        "        clear_output(True)\n",
        "        plt.plot(train_loss_set)\n",
        "        plt.title(\"Training loss\")\n",
        "        plt.xlabel(\"Batch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.show()\n",
        "    \n",
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n",
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5NQmPbJODeRa",
        "outputId": "d8649007-842c-49a3-f368-4d78afff84b1"
      },
      "source": [
        "print(classification_report(valid_labels, valid_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# Оценка качества на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mAN0LZBOOPVh"
      },
      "source": [
        "tokenized_texts = [[\"[CLS]\"] + tokenizer.tokenize(sent)[:510]  + [\"[SEP]\"] for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZchvRBEYYBD1"
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NUZqhoCXYBD3",
        "outputId": "eee15ecd-33c9-4152-ed99-7657a9adb3d7"
      },
      "source": [
        "print(classification_report(test_labels, test_preds))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r6Hi7RXyHvMJ"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz2g4l7wKTr3"
      },
      "source": [
        "copy_df = test_df.copy()\n",
        "copy_df[\"predict\"] = test_preds\n",
        "\n",
        "copy_df.to_excel(\"test.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}